{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Fine tuning LM for QA<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#读取\" data-toc-modified-id=\"读取-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>读取</a></span><ul class=\"toc-item\"><li><span><a href=\"#分词器\" data-toc-modified-id=\"分词器-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>分词器</a></span></li><li><span><a href=\"#find-top-K-sents\" data-toc-modified-id=\"find-top-K-sents-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>find top K sents</a></span></li><li><span><a href=\"#测试find-span\" data-toc-modified-id=\"测试find-span-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>测试find span</a></span></li><li><span><a href=\"#计算span\" data-toc-modified-id=\"计算span-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>计算span</a></span></li></ul></li><li><span><a href=\"#初始化\" data-toc-modified-id=\"初始化-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>初始化</a></span></li><li><span><a href=\"#QA-dataset\" data-toc-modified-id=\"QA-dataset-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>QA dataset</a></span></li><li><span><a href=\"#LSTM-GRU\" data-toc-modified-id=\"LSTM-GRU-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>LSTM GRU</a></span></li><li><span><a href=\"#排列组合\" data-toc-modified-id=\"排列组合-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>排列组合</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "from apex import amp\n",
    "\n",
    "from classes import *\n",
    "from GNN import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "# Restore\n",
    "classifier = GAT_HotpotQA(features=768, hidden=32, nclass=2, dropout=0.2, alpha=0.3, nheads=8, nodes_num=450)\n",
    "classifier.to('cuda')\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, classifier.parameters()),\n",
    "                      lr=1e-3)\n",
    "checkpoint = torch.load('save_cache/GNN_HotpotQA.pt')\n",
    "\n",
    "opt_level = 'O1'\n",
    "classifier, optimizer = amp.initialize(classifier, optimizer, opt_level=opt_level)\n",
    "\n",
    "classifier.load_state_dict(checkpoint['model'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "amp.load_state_dict(checkpoint['amp'])\n",
    "\n",
    "# Continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccb136571b14e5fb1f699ee246e80df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='loading 0~10', max=10.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HotpotQA Dataset. mode: train. size: 7. max_seq: 450\n"
     ]
    }
   ],
   "source": [
    "dataset = HotpotQA_Dataset_New.build_dataset(i_from = 0,i_to = 10)\n",
    "dataset.set_parameters(450, 0)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分词器\n",
    "\n",
    "```python\n",
    "classtransformers.XLNetTokenizer(vocab_file, do_lower_case=False, remove_space=True, keep_accents=False, bos_token='<s>', eos_token='</s>', unk_token='<unk>', sep_token='<sep>', pad_token='<pad>', cls_token='<cls>', mask_token='<mask>', additional_special_tokens=['<eop>', '<eod>'], **kwargs)\n",
    "\n",
    "batch_encode_plus(batch_text_or_text_pairs: Union[str, List[str]], add_special_tokens: bool = True, max_length: Optional[int] = None, stride: int = 0, truncation_strategy: str = 'longest_first', pad_to_max_length: bool = False, return_tensors: Optional[str] = None, return_token_type_ids: Optional[bool] = None, return_attention_masks: Optional[bool] = None, return_overflowing_tokens: bool = False, return_special_tokens_masks: bool = False, return_offsets_mapping: bool = False, return_input_lengths: bool = False, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "\n",
    "model_name = 'xlnet-base-cased'\n",
    "\n",
    "proxies={\"http_proxy\": \"127.0.0.1:10809\",\n",
    "         \"https_proxy\": \"127.0.0.1:10809\"}\n",
    "proxies=None\n",
    "\n",
    "tokenizer_XLNET = AutoTokenizer.from_pretrained(model_name,proxies=proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[113, 92, 27, 36, 82, 36, 27, 664, 17, 155, 26, 12431, 9, 4, 3]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_XLNET.encode('what time is it? it is 9 o\\'clock.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk><s></s><cls><sep><pad><mask><eod><eop>.()\"-–£€\n"
     ]
    }
   ],
   "source": [
    "ii = [i for i in range(0,18)]\n",
    "print(tokenizer_XLNET.decode(ii))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[160, 41, 44]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_XLNET.encode(('how are you'),add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    5,     5,     5,     5,   113,    92,    27,    36,    82,     4,\n",
       "             36,    27,   664,    17,   155,    26, 12431,     9,     4,     3],\n",
       "         [    5,     5,     5,     5,     5,     5,     5,     5,     5,   160,\n",
       "             41,    44,    82,     4,    17,   150,   569,  1592,     4,     3]]),\n",
       " 'token_type_ids': tensor([[3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2],\n",
       "         [3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2]]),\n",
       " 'attention_mask': tensor([[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_XLNET.batch_encode_plus([('what time is it?', 'it is 9 o\\'clock.'),\n",
    "                       ('how are you?', 'i am fine')], max_length = 20, pad_to_max_length=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, my dog is cute<sep><cls>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([   17, 11368,    19,    94,  2288,    27, 10920,     4,     3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dict_for_LM['input_ids']\n",
    "batch_dict_for_LM['token_type_ids']\n",
    "batch_dict_for_LM['attention_mask']\n",
    "batch_dict_for_LM['start_positions']\n",
    "batch_dict_for_LM['end_positions']\n",
    "batch_dict_for_LM['is_impossible']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find top K sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_dict in gen_batches(dataset,\n",
    "                                batch_size=7, \n",
    "                                device='cuda'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['feature_matrix', 'adj', 'sent_mask', 'para_mask', 'labels', 'answer_type', 'ans_yes_no', 'ques_tokens', 'answer_tokens', 'sent_tokens'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dict.keys()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logits_sent, logits_para, logits_Qtype = \\\n",
    "                                classifier(batch_dict['feature_matrix'], batch_dict['adj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def find_ans_spans(target, tokens, offets_type = 'position', top_num = None):\n",
    "    assert offets_type in ['position', 'range'] and \\\n",
    "        type(target) == type(tokens) == list\n",
    "    len_x1 = len(target)\n",
    "    len_x2 = len(tokens)\n",
    "    if len_x1 == 0 or len_x2 == 0 or len_x1 > len_x2:\n",
    "        return [0,0]\n",
    "    \n",
    "    i1=0\n",
    "    i2=0\n",
    "    i2_current = 0\n",
    "    spans = []\n",
    "    while i2 <= len_x2 - len_x1:\n",
    "        if top_num and len(spans) == top_num: # early stop\n",
    "            break\n",
    "        i2_current = i2\n",
    "        while i1 < len_x1:\n",
    "            if target[i1] != tokens[i2]: \n",
    "                i1 = 0\n",
    "                i2 = i2_current + 1\n",
    "                break\n",
    "            else:\n",
    "                i1 += 1\n",
    "                i2 += 1\n",
    "                \n",
    "        if not i1 < len_x1:\n",
    "            i1 = 0\n",
    "            if offets_type == 'position':  \n",
    "                spans.append((i2_current, i2_current+len_x1-1))\n",
    "            else:\n",
    "                spans.append((i2_current, i2_current+len_x1))\n",
    "                \n",
    "    return spans[:top_num+1] if top_num else spans[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def convert_batch_to_LM(classifier, batch_dict, topN = 4, \n",
    "                        max_length = 20, device = 'cpu'):\n",
    "    '''convert batch from GNN to LM model(QA fine-tuning)'''\n",
    "    batch_dict_for_LM = {}\n",
    "    \n",
    "    logits_sent, _, logits_Qtype = classifier(batch_dict['feature_matrix'], batch_dict['adj'])\n",
    "    # logits_Qtype: [B, 2]  1:yesno, 0:span\n",
    "    _, predict_Qtype = torch.max(logits_Qtype, dim=-1).tolist()\n",
    "    topN_sents = []\n",
    "    \n",
    "    # choose top 4 sents\n",
    "    for batch_index in range(batch_dict['sent_mask'].shape[0]):\n",
    "        sent_index = torch.nonzero(batch_dict['sent_mask'][batch_index].view(-1,).long()).flatten()\n",
    "        sent_logits = torch.index_select(logits_sent[batch_index], 0, sent_index)\n",
    "        sent_logits_soft = F.softmax(sent_logits, dim = -1).cpu()\n",
    "        value, _index = torch.max(sent_logits_soft, dim=-1)\n",
    "        sent_scores = value.tolist()\n",
    "        sent_score_index = [(score, index) for score, index in zip(sent_scores, range(len(sent_scores)))]\n",
    "        sent_score_index_sort = sorted(sent_score_index,key=lambda x:x[0], reverse=True)\n",
    "        sent_indexes = [x[-1] for x in sent_score_index_sort[:topN]]\n",
    "        topN_sents.append(sent_indexes)\n",
    "        \n",
    "    batch_sent_tokens = []\n",
    "    for batch_index, sents in enumerate(topN_sents):\n",
    "        temp = []\n",
    "        for i_sent in sents: temp.extend(batch_dict['sent_tokens'][batch_index][i_sent])\n",
    "        batch_sent_tokens.append(temp)\n",
    "\n",
    "    batch_ques_sent = [(batch_dict['ques_tokens'],sent_tokens) for sent_tokens in batch_sent_tokens]\n",
    "    \n",
    "    # build start-end positions\n",
    "    ans_idx = tokenizer_XLNET.encode(batch_dict['answer_tokens'], add_special_tokens=False)\n",
    "    start_end_list = []\n",
    "    \n",
    "    res = tokenizer_XLNET.batch_encode_plus(batch_ques_sent, \n",
    "                                            max_length = max_length, \n",
    "                                            pad_to_max_length=True, return_tensors='pt')\n",
    "    \n",
    "    batch_dict_for_LM['input_ids'] = res['input_ids']\n",
    "    batch_dict_for_LM['token_type_ids'] = res['token_type_ids']\n",
    "    batch_dict_for_LM['attention_mask'] = res['attention_mask']\n",
    "    \n",
    "    bsz = batch_dict_for_LM['input_ids'].shape[0]\n",
    "    tokens = batch_dict_for_LM['input_ids'].tolist()\n",
    "    start_end_list = [find_ans_spans(ans_idx, input_ids, top_num = 1) \\\n",
    "                      for i in range(bsz) \\\n",
    "                      for input_ids in tokens[i]]\n",
    "    \n",
    "#     is_impossible = []\n",
    "    start_positions, end_positions = [], []\n",
    "    for s_e in start_end_list:\n",
    "        if s_e == []: \n",
    "#             is_impossible.append(1)\n",
    "            start_positions.append(9e9)\n",
    "            end_positions.append(9e9)\n",
    "        else:\n",
    "#             is_impossible.append(0)\n",
    "            start_positions.append(s_e[0])\n",
    "            end_positions.append(s_e[1])          \n",
    "\n",
    "#     batch_dict_for_LM['is_impossible'] = torch.tensor(is_impossible)\n",
    "    batch_dict_for_LM['start_positions'] = torch.tensor(start_positions)\n",
    "    batch_dict_for_LM['end_positions'] = torch.tensor(end_positions)\n",
    "\n",
    "    for k in batch_dict_for_LM.keys():\n",
    "        batch_dict_for_LM[k] = batch_dict_for_LM[k].to(device)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "topN_sents_one_batch(batch_dict,logits_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_index = torch.nonzero(batch_dict['sent_mask'][0].view(-1,).long()).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2,  10,  14,  22,  31,  33,  36,  43,  49,  54,  58,  66,  72,  74,\n",
       "         77,  79,  81,  85,  89,  93,  97, 101, 105, 106, 108, 112, 117, 121,\n",
       "        123, 127, 130, 134, 138, 143, 148, 151, 157])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_index.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([37])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_dict['sent_tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([37, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_logits = torch.index_select(logits_sent[0], 0, sent_index)\n",
    "sent_logits_soft = F.softmax(sent_logits, dim = -1).cpu()\n",
    "sent_logits_soft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value, _index = torch.max(sent_logits_soft, dim=-1)\n",
    "sent_scores = value.cpu().tolist()\n",
    "len(sent_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_score_index = [(score, index) for score, index in zip(sent_scores, range(len(sent_scores)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 14, 12, 16]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_score_index_sort = sorted(sent_score_index,key=lambda x:x[0],reverse=True)\n",
    "sent_indexes = [x[-1] for x in sent_score_index_sort[:4]]\n",
    "sent_indexes\n",
    "# 获取batch中一个元素的前4句."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试find span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁It', '▁was', '▁founded', '▁in', '▁Pine', '▁Bluff', ',', '▁Arkansas', '▁in', '▁1986', '.', '▁Cardinal', '▁Health', '▁also', '▁owns', '▁the', '▁franchise', '▁chain', '▁The', '▁Medicine', '▁Shop', 'pe', '.', '▁Leader', '▁Drug', '▁Store', 's', '▁is', '▁a', '▁network', '▁of', '▁over', '▁3', ',', '100', '▁independently', '▁owned', '▁and', '▁operated', '▁pharmacies', '.', '▁Gray', '▁Drug', '▁was', '▁a', '▁drug', 'store', '▁chain', '▁in', '▁Cleveland', ',', '▁Ohio', '.']\n"
     ]
    }
   ],
   "source": [
    "sent_tokens = batch_dict['sent_tokens']\n",
    "\n",
    "sent_final_tokens = []\n",
    "for i in sent_indexes: sent_final_tokens.extend(sent_tokens[0][i])\n",
    "print(sent_final_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_tokens_test =  ['▁network', '▁of', '▁over']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_tokens_test in sent_final_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁network', '▁of', '▁over']\n",
      "['▁network', '▁of']\n"
     ]
    }
   ],
   "source": [
    "print(answer_tokens_test)\n",
    "print(sent_final_tokens[29:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def find_ans_spans(target, tokens, offets_type = 'position', top_num = None):\n",
    "    assert offets_type in ['position', 'range'] and \\\n",
    "        type(target) == type(tokens) == list\n",
    "    len_x1 = len(target)\n",
    "    len_x2 = len(tokens)\n",
    "    if len_x1 == 0 or len_x2 == 0 or len_x1 > len_x2:\n",
    "        return [0,0]\n",
    "    \n",
    "    i1=0\n",
    "    i2=0\n",
    "    i2_current = 0\n",
    "    spans = []\n",
    "    while i2 <= len_x2 - len_x1:\n",
    "        if top_num and len(spans) == top_num:\n",
    "            break\n",
    "        i2_current = i2\n",
    "        while i1 < len_x1:\n",
    "            if target[i1] != tokens[i2]: \n",
    "                i1 = 0\n",
    "                i2 = i2_current + 1\n",
    "                break\n",
    "            else:\n",
    "                i1 += 1\n",
    "                i2 += 1\n",
    "                \n",
    "        if not i1 < len_x1:\n",
    "            i1 = 0\n",
    "            if offets_type == 'position':  \n",
    "                spans.append([i2_current, i2_current+len_x1-1])\n",
    "            else:\n",
    "                spans.append([i2_current, i2_current+len_x1])\n",
    "                \n",
    "    return spans[:top_num+1] if top_num else spans[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[29, 31]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_ans_spans(answer_tokens_test, sent_final_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算span\n",
    "\n",
    "将`ques_feature`和`content_features`加上`[SEP] [CLS]`拼接在一起."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_tokens_test2 = [ 'Australian', 'GT', 'Championship',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens_combine = []\n",
    "for s_index in sent_indexes: sent_tokens_combine.extend(sent_tokens[0][s_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tokens = ['<x1>','[ques]','<x2>'] + sent_tokens_combine + ['<cls>']\n",
    "ans_spans = find_ans_spans(answer_tokens_test2, final_tokens, top_num = 2)\n",
    "ans_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import ujson as json\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "json_train_path = r'./data/hotpot_train_v1.1.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "\n",
    "model_path = '/g/data/models/xlnet-base-cased'\n",
    "tokenizer_XLNET = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/g/data/models/xlnet-base-cased/spiece.model',\n",
       " '/g/data/models/xlnet-base-cased/special_tokens_map.json',\n",
       " '/g/data/models/xlnet-base-cased/added_tokens.json')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_XLNET.save_pretrained('/g/data/models/xlnet-base-cased/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['supporting_facts', 'level', 'question', 'context', 'answer', '_id', 'type'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(json_train_path, 'r', encoding='utf-8') as fp:\n",
    "    json_train = json.load(fp)\n",
    "    \n",
    "json_train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = json_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90447"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "from datasets import HotpotQA_QA_Dataset, find_ans_spans, generate_QA_batches\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = HotpotQA_QA_Dataset.build_dataset('data/hotpot_train_mini.json')\n",
    "# tt = HotpotQA_QA_Dataset.build_dataset('data/hotpot_train_v1.1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('data/models/bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BertTokenizer'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(type(tokenizer)).split('.')[-1].split('\\'')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 20844, 178, 1821, 23220, 1306, 119, 102]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('hi i am jim.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PAD] [unused1] [unused2] [unused3] [unused4] [unused5] [unused6] [unused7] [unused8] [unused9]'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([i for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'special_tokens_mask': tensor([[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1]]),\n",
       " 'input_ids': tensor([[  101, 19082,   178,  1821, 23220,  1306,   102,  1293,  1132,  1128,\n",
       "            119,   178,  1821,  2503, 24438,  1775,   102,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_encode_plus([('hello i am jim', 'how are you. i am fine thx')],\n",
    "                           return_special_tokens_masks=True,\n",
    "                           pad_to_max_length=True,\n",
    "                           max_length=30,\n",
    "                           return_token_type_ids=True,\n",
    "                           return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sep_token_id"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tokenizer.decode([0, 61, 940, 557, 2737, 16, 2034, 11, 7050, 10873, 9910, 2862, 45480, 741, 40415, 1564, 50, 1690, 260, 1891, 2737])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HotpotQA QA Dataset. mode: train. size: 350. sents num: 4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.set_parameters(tokenizer = tokenizer,topN_sents=4, max_length=512, uncased=True, permutations=False)\n",
    "tt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tt.set_split('train')\n",
    "tt.__getitem__(0,detail_mod=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "for i in generate_QA_batches(tt,1):\n",
    "    \n",
    "    for k,v in i.items():\n",
    "        print(k)\n",
    "        print(v.shape)\n",
    "        print('')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n",
      "train 46. 5ae0d91e55429924de1b7198 no answer: 2006\tsupport sent: 5\n"
     ]
    }
   ],
   "source": [
    "tt.check_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supporting_facts: [['Just the Two of Us (Grover Washington Jr. song)', 0], ['Just the Two of Us (Grover Washington Jr. song)', 2], ['Bette Davis Eyes', 0], ['Bette Davis Eyes', 1]]\n",
      "answer: nine\n",
      "\n",
      "Just the Two of Us (Grover Washington Jr. song)\n",
      "\"Just the Two of Us\" is a 1981 R&B single written by Bill Withers, William Salter and Ralph MacDonald, which was recorded by Grover Washington Jr. and Bill Withers.\n",
      "Just the Two of Us (Grover Washington Jr. song)\n",
      " An edited version reached number two on the \"Billboard\" Hot 100, staying there for 3 weeks, behind \"Morning Train (9 to 5)\" by Sheena Easton and \"Bette Davis Eyes\" by Kim Carnes.\n",
      "Bette Davis Eyes\n",
      "\"Bette Davis Eyes\" is a song written and composed by Donna Weiss and Jackie DeShannon, and made popular by American singer Kim Carnes.\n",
      "Bette Davis Eyes\n",
      " DeShannon recorded it in 1974; Carnes's 1981 version spent nine weeks at No. 1 on the \"Billboard\" Hot 100 and was \"Billboard\"' s biggest hit of 1981.\n"
     ]
    }
   ],
   "source": [
    "tt.check_supporting_facts('5a904e725542995651fb5118')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.set_split('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "50\n",
      "val\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "tt.set_split('train')\n",
    "print('train')\n",
    "for i in range(350):\n",
    "    temp = tt.__getitem__(i)\n",
    "    if int(temp['start_positions'].item()) == 115:\n",
    "        print(i)\n",
    "tt.set_split('val')\n",
    "print('val')\n",
    "for i in range(150):\n",
    "    temp = tt.__getitem__(i)\n",
    "    if int(temp['start_positions'].item()) == 115:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emprise bank has branches in a city situated along what river \n",
      "[('emprise bank has branches in a city situated along what river ', 'emprise bank emprise bank is a kansas based family owned community bank headquartered in wichita kansas with more than 1 billion in assets  emprise bank emprise has 37 locations across the state of kansas including branches in wichita andover augusta chanute clearwater council grove derby el dorado eureka goddard hays haysville hillsboro humboldt iola lawrence mcpherson moran mulvane park city potwin rose hill and valley center  humboldt kansas humboldt is a city in allen county kansas united states  humboldt kansas it is situated along the neosho river ')]\n",
      "neosho river\n",
      "[4368, 9468, 341]\n",
      "input_remove_quesid\n",
      "[2, -99, -99, -99, -99, -99, -99, -99, -99, -99, -99, -99, -99, -99, 3, 16453, 11864, 965, 16453, 11864, 965, 25, 21, 3831, 432, 190, 1467, 514, 965, 9511, 19, 21666, 3831, 29, 91, 119, 137, 2786, 19, 6223, 16453, 11864, 965, 16453, 11864, 63, 4294, 4095, 464, 14, 146, 16, 3831, 215, 4395, 19, 21666, 17, 2549, 15774, 6122, 6567, 1207, 2831, 516, 5695, 6473, 931, 107, 14293, 24081, 24721, 4301, 18, 4301, 5921, 948, 20101, 21410, 31, 2268, 4439, 26959, 16378, 6633, 2686, 62, 405, 136, 3997, 4181, 1092, 948, 17, 1152, 459, 21410, 3831, 21410, 25, 21, 136, 19, 3675, 271, 3831, 181, 202, 21410, 3831, 32, 25, 2692, 303, 14, 4368, 9468, 341, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2, 16453, 11864,   965,    63,  4395,    19,    21,   136,  2692,\n",
       "            303,    98,   341,     3, 16453, 11864,   965, 16453, 11864,   965,\n",
       "             25,    21,  3831,   432,   190,  1467,   514,   965,  9511,    19,\n",
       "          21666,  3831,    29,    91,   119,   137,  2786,    19,  6223, 16453,\n",
       "          11864,   965, 16453, 11864,    63,  4294,  4095,   464,    14,   146,\n",
       "             16,  3831,   215,  4395,    19, 21666,    17,  2549, 15774,  6122,\n",
       "           6567,  1207,  2831,   516,  5695,  6473,   931,   107, 14293, 24081,\n",
       "          24721,  4301,    18,  4301,  5921,   948, 20101, 21410,    31,  2268,\n",
       "           4439, 26959, 16378,  6633,  2686,    62,   405,   136,  3997,  4181,\n",
       "           1092,   948,    17,  1152,   459, 21410,  3831, 21410,    25,    21,\n",
       "            136,    19,  3675,   271,  3831,   181,   202, 21410,  3831,    32,\n",
       "             25,  2692,   303,    14,  4368,  9468,   341,     3,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0]]),\n",
       " 'token_type_ids': tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0]]]),\n",
       " 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0]]]),\n",
       " 'special_tokens_mask': tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1]]]),\n",
       " 'start_positions': tensor([[115]]),\n",
       " 'end_positions': tensor([[117]]),\n",
       " 'yes_no_span': tensor([[-100]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.set_split('train')\n",
    "tt.__getitem__(50 ,detail_mod=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([2, 16453, 11864,   965,    63,  4395,    19,    21,   136,  2692,\n",
    "            303,    98,   341,     3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([2, -99, -99, -99, -99, -99, -99, -99, -99, -99, -99, -99, -99, -99, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tt.__getitem__(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0]])\n"
     ]
    }
   ],
   "source": [
    "print(temp['special_tokens_mask'].view(-1, 512).gather(-1, temp['end_positions'].view(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq[117]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  35,   75,   48,   82,   30,   62,   15,   12,   83,   26,   31,   85,\n",
      "          43, -100,   37,   52,   48,   60,   68,   88,   55,   86,   56,    8,\n",
      "          49,   81,  186,  198,   84,   60,   59,   44])\n",
      "tensor([  52,   13, -100,   64,   35,   41,   36,   57,   55,  130,   28,   31,\n",
      "          35,   47,  138,   79,   60,   55,  115,   53,   27,   53,   23,   78,\n",
      "         113,   39,   74,   72,   30,   66,   40,   46])\n",
      "tensor([  49,  147,    6,  103, -100,   67,    6,   59,   26,   43,   48,   99,\n",
      "        -100,   28,   87,   16,   35,   78,   80,   89,   10,  126,   64,   15,\n",
      "          54,   78,   71,   63,  128,   59,   60,   73])\n",
      "tensor([ 72,  12,  59,  33,  43, 103,  70,  56,  19,  51,  74,  35,  39,  29,\n",
      "         68,  59,  57,  85,  16,  98,  54,  55,  88,  55, 115,  91,  69,  43,\n",
      "         17,  92,  49,  83])\n",
      "tensor([ 76,  69,  86, 102,   2,  55,  10,  14,  18,  55,  52,  14, 103,  42,\n",
      "         43,  23,  44,  82,  27, 116, 126,  39,  46, 119,  24,  80,  43, 110,\n",
      "         11,  76, 144,  22])\n",
      "tensor([  73,   26,  103,   54,   15,   57,   37,   26,    8,   91,   85,   35,\n",
      "          60,  136,   19,   73,   92,   50,   41,   45,   68,   35,   76,   86,\n",
      "          37,   99,   69,   58,   60, -100,   66,   62])\n",
      "tensor([   9,   41,   39,   73,   70,   89, -100,   38,   93,   31,  108,   97,\n",
      "          76,   50,   66,   61,   41,   45,   45,  115, -100,   50,   30,   32,\n",
      "          64,   77,   13, -100,   30,  144,   65,   22])\n",
      "tensor([  27,   31,   33,   53,   76,  114,  104,    2,   89,   59,   83, -100,\n",
      "          59,   21,   45,   13,   40,   47,   64,    7,  169,   32,  126,   14,\n",
      "          59,   51,   48,  110,   20,    6,   73,   77])\n",
      "tensor([  16,   41,   95,   50,   69,  133,   97,   51,  142,   31,   72, -100,\n",
      "          84,   87,   51,   66,   69,  100,   60,   59,   57,  103,   79,   83,\n",
      "          49,   76,   87,   27,   30,   58,   50,   34])\n",
      "tensor([  52,   30,   58, -100,   43,    4,   49,  106,   54,   15, -100, -100,\n",
      "         101,   98,   94,   78,   63,   41,   40,   38,   15,   73,   59,   45,\n",
      "          40,  121,   12,   71,   26,    8,   19,   85])\n"
     ]
    }
   ],
   "source": [
    "for batch in generate_QA_batches(tt,32, shuffle=False):\n",
    "    print(batch['start_positions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "tt.get_item_err_detail_by_id('adf9e7e5542992d7e9f93be')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5ab4c2925542996a3a969fc5 no answer: south america\tsupport sent: 2\n",
      "5a8299e255429954d2e2eb76 no answer: benjamin wills newton\tsupport sent: 9\n",
      "5a7b23ca554299042af8f703 index err.\n",
      "5a8f81d955429918e830d248 no answer: flowering plant\tsupport sent: 2\n",
      "5ae7b41c5542997ec27276d5 no answer: play\tsupport sent: 2\n",
      "5add33c05542992c1e3a2562 no answer: north korea\tsupport sent: 3\n",
      "5abc573d55429959677d6a8a no answer:  full metal panic rpg \tsupport sent: 3\n",
      "5ae2168f554299495565d9f7 no answer:  temperatures rising \tsupport sent: 8\n",
      "5a8a317455429930ff3c0cef index err.\n",
      "5adf8f98554299025d62a2bf no answer: degree\tsupport sent: 5\n",
      "5abbb29c5542993f40c73b7f no answer: venezuela\tsupport sent: 2\n",
      "5ab6460b5542995eadeeff96 index err.\n",
      "5ade637955429939a52fe897 no answer: south africa\tsupport sent: 2\n",
      "5a8051055542992bc0c4a6f7 no answer:  \tsupport sent: 3\n",
      "5a865501554299211dda2af6 no answer: howard g kazanjian\tsupport sent: 8\n",
      "5ae3d5bb5542994393b9e77f no answer: south korea\tsupport sent: 2\n",
      "5addee6e5542997dc79070c0 no answer: south korea\tsupport sent: 2\n",
      "5adf53885542995ec70e8fc5 no answer: south korea\tsupport sent: 2\n",
      "5ab273ee5542997061209606 index err.\n",
      "5addbc485542995b365fab74 no answer: south korea\tsupport sent: 3\n",
      "5abe4bb855429965af743eb8 index err.\n",
      "5ae21536554299495565d9f0 no answer: august\tsupport sent: 7\n",
      "5ae752915542991bbc9761e8 no answer: europe\tsupport sent: 2\n",
      "5abd1b995542992ac4f381db no answer: warner bros pictures\tsupport sent: 7\n",
      "5ae609e45542996de7b71b0a no answer: japanese attack on pearl harbor\tsupport sent: 8\n",
      "5abfedab5542997d6429594b no answer: amélie simone mauresmo born 5 july 1979 is a french former professional tennis player and a former world no 1 mauresmo won two grand slam singles titles at the australian open and at wimbledon and also won a silver medal at the 2004 summer olympics \tsupport sent: 2\n",
      "5ade61d8554299728e26c703 no answer: 1\tsupport sent: 2\n",
      "5ac0894a5542992a796ded38 no answer: romania\tsupport sent: 3\n",
      "5a8110e555429926c1cdace3 no answer: india\tsupport sent: 2\n",
      "5ae1daa3554299492dc91ba5 no answer: romania\tsupport sent: 3\n",
      "5adf9eae5542995ec70e9053 no answer: menid empi\tsupport sent: 2\n",
      "5a84b67c5542991dd0999da7 no answer: warner bros entertainment inc \tsupport sent: 4\n",
      "5a7c8a1b55429935c91b5203 no answer: portrait\tsupport sent: 2\n",
      "5abdc8a25542993f32c2a055 no answer: swanston street\tsupport sent: 2\n",
      "5a8f3aac55429918e830d1db no answer: warner bros pictures\tsupport sent: 2\n",
      "5ab61cce55429953192ad25c no answer: field equations\tsupport sent: 7\n",
      "5ae0e2df5542990adbacf6b1 index err.\n",
      "5a8d6138554299585d9e37c7 index err.\n",
      "5a8164fb5542995ce29dcbf6 index err.\n",
      "5adbd1855542996e68525251 no answer: africa\tsupport sent: 2\n",
      "5a7ff32f5542992e7d278dc7 no answer: peru\tsupport sent: 2\n",
      "5ac2b03b554299677310260b no answer: europe\tsupport sent: 2\n",
      "5adc0cc855429947ff1738e1 no answer: joão pedro rodrigues is a portuguese film director he is considered to be part of the school of reis film family \tsupport sent: 3\n",
      "5a8c7b125542995e66a47614 index err.\n",
      "5a847c91554299123d8c2268 index err.\n",
      "5adf75485542995ec70e901a no answer:  \tsupport sent: 2\n",
      "5ae2eac355429928c4239557 no answer: flower\tsupport sent: 2\n",
      "5a74781355429929fddd843c no answer: john michael ozzy osbourne born 3 december 1948 is an english singer songwriter and actor he rose to prominence in the early 1970s as the lead vocalist of the heavy metal band black sabbath \tsupport sent: 4\n",
      "5a7e5b2455429934daa2fc10 index err.\n"
     ]
    }
   ],
   "source": [
    "tt.check_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unit'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([1237])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8481]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('China',add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 2757,\n",
       " 11,\n",
       " 17087,\n",
       " 260,\n",
       " 16517,\n",
       " 6,\n",
       " 436,\n",
       " 131,\n",
       " 24,\n",
       " 16,\n",
       " 223,\n",
       " 5,\n",
       " 942,\n",
       " 9,\n",
       " 20045,\n",
       " 4987,\n",
       " 24181,\n",
       " 2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('division in Hunan Province, China; it is under the administration of Zhuzhou')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from transformers import XLNetForQuestionAnswering\n",
    "\n",
    "model_path = '/g/data/models/xlnet-base-cased'\n",
    "\n",
    "model = XLNetForQuestionAnswering.from_pretrained(model_path,local_files_only=True)\n",
    "_ = model.eval()\n",
    "_ = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5179,  0.1814,  1.5070, -0.0687,  1.6602],\n",
      "        [ 1.2503, -1.4755, -0.1997, -1.9947, -0.7214],\n",
      "        [-1.1893, -1.5768,  0.7894,  1.2449, -0.5401]], requires_grad=True)\n",
      "tensor([   0,    1, -100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.6039, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print(input)\n",
    "# target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "target = torch.tensor([0,1,-100], dtype=torch.long)\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from XLNET_QA_model import XLNetForQuestionAnswering_customized as XLNetQAModel\n",
    "\n",
    "model_path = '/g/data/models/xlnet-base-cased'\n",
    "\n",
    "model = XLNetQAModel.from_pretrained(model_path,local_files_only=True)\n",
    "_ = model.eval()\n",
    "_ = model.to('cuda')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "forward(input_ids=None, attention_mask=None, mems=None, perm_mask=None, target_mapping=None, token_type_ids=None, input_mask=None, head_mask=None, inputs_embeds=None, start_positions=None, end_positions=None, is_impossible=None, cls_index=None, p_mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0,
     18
    ]
   },
   "outputs": [],
   "source": [
    "def compute_span_accuracy(start_logits, start_positions, end_logits, end_positions):\n",
    "\n",
    "    _, start_indices = start_logits.max(-1)\n",
    "    start_indices.eq(start_positions)\n",
    "\n",
    "    _, end_indices = end_logits.max(-1)\n",
    "    end_indices.eq(end_positions)\n",
    "\n",
    "    correct = start_indices.eq(start_positions) * end_indices.eq(end_positions)\n",
    "\n",
    "    numerator = correct.sum().item()\n",
    "    denominator = start_positions.ne(-100).sum().item()\n",
    "\n",
    "    # all questions are yes-no type.\n",
    "    if denominator == 0: return 0\n",
    "\n",
    "    return float(numerator) / denominator\n",
    "\n",
    "def compute_accuracy(logits, labels):\n",
    "\n",
    "    _, logits_indices = logits.max(-1)    \n",
    "\n",
    "    numerator = torch.eq(logits_indices, labels).sum().item()\n",
    "    denominator = labels.ne(-100).sum().item()\n",
    "\n",
    "    if denominator == 0: return 0\n",
    "    return float(numerator) / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "for batch in generate_QA_batches(tt, 16, device='cuda'):\n",
    "    yes_no_span = batch.pop('yes_no_span')\n",
    "\n",
    "    res = model(**batch)\n",
    "    \n",
    "    start_logits, end_logits, cls_logits = res[0], res[1], res[2]\n",
    "    \n",
    "\n",
    "    start_loss = loss_fct(start_logits, batch['start_positions'])\n",
    "    end_loss = loss_fct(end_logits, batch['end_positions'])\n",
    "    \n",
    "    start_end_loss = (start_loss + end_loss) / 2\n",
    "    cls_loss = loss_fct(cls_logits, yes_no_span) * 0.5\n",
    "\n",
    "    span_accuracy = compute_span_accuracy(start_logits, batch['start_positions'],\n",
    "                                                end_logits, batch['end_positions'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k,v in batch.items():\n",
    "    print(k)\n",
    "    print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['end_positions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['yes_no_span']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start_top_log_probs\n",
    "start_top_index\n",
    "end_top_log_probs\n",
    "end_top_index\n",
    "cls_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in res:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits = torch.tensor([\n",
    "    [1,6,3,4,5],\n",
    "    [1,2,5,4,2]\n",
    "])\n",
    "end_logits = torch.tensor([\n",
    "    [1,2,3,4,5],\n",
    "    [1,2,5,4,6]\n",
    "])\n",
    "\n",
    "start_positions = torch.tensor([3,4])\n",
    "end_positions = torch.tensor([4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(logits, labels):\n",
    "    \n",
    "    _, logits_indices = logits.max(-1)    \n",
    "    \n",
    "    numerator = torch.eq(logits_indices, labels).sum().item()\n",
    "    denominator = labels.ne(-100).sum().item()\n",
    "    \n",
    "    if denominator == 0: return 0\n",
    "    return float(numerator) / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn([3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor([-100,0,0,0,1])\n",
    "labels = labels.index_select(dim=-1, index=labels.ne(-100).long())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.ne(-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM GRU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input = torch.randn(3, 5, 7)\n",
    "h0 = torch.randn(2*2, 3, 7)\n",
    "c0 = torch.randn(2*2, 3, 7)\n",
    "rnn = nn.LSTM(input_size=input.shape[-1], hidden_size=7, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 14])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hn, cn) = rnn(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input = torch.randn(3, 5, 7)\n",
    "\n",
    "rnn = nn.GRU(input_size=input.shape[-1], hidden_size=7, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
    "output, hn = rnn(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 14])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "pretrained_model_path = 'data/models/xlnet-base-cased'\n",
    "from QA_models import AutoQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_path, local_files_only=True)\n",
    "model = AutoQuestionAnswering.from_pretrained(pretrained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.mask_emb\n",
      "transformer.word_embedding.weight\n",
      "transformer.layer.0.rel_attn.q\n",
      "transformer.layer.0.rel_attn.k\n",
      "transformer.layer.0.rel_attn.v\n",
      "transformer.layer.0.rel_attn.o\n",
      "transformer.layer.0.rel_attn.r\n",
      "transformer.layer.0.rel_attn.r_r_bias\n",
      "transformer.layer.0.rel_attn.r_s_bias\n",
      "transformer.layer.0.rel_attn.r_w_bias\n",
      "transformer.layer.0.rel_attn.seg_embed\n",
      "transformer.layer.0.rel_attn.layer_norm.weight\n",
      "transformer.layer.0.rel_attn.layer_norm.bias\n",
      "transformer.layer.0.ff.layer_norm.weight\n",
      "transformer.layer.0.ff.layer_norm.bias\n",
      "transformer.layer.0.ff.layer_1.weight\n",
      "transformer.layer.0.ff.layer_1.bias\n",
      "transformer.layer.0.ff.layer_2.weight\n",
      "transformer.layer.0.ff.layer_2.bias\n",
      "transformer.layer.1.rel_attn.q\n",
      "transformer.layer.1.rel_attn.k\n",
      "transformer.layer.1.rel_attn.v\n",
      "transformer.layer.1.rel_attn.o\n",
      "transformer.layer.1.rel_attn.r\n",
      "transformer.layer.1.rel_attn.r_r_bias\n",
      "transformer.layer.1.rel_attn.r_s_bias\n",
      "transformer.layer.1.rel_attn.r_w_bias\n",
      "transformer.layer.1.rel_attn.seg_embed\n",
      "transformer.layer.1.rel_attn.layer_norm.weight\n",
      "transformer.layer.1.rel_attn.layer_norm.bias\n",
      "transformer.layer.1.ff.layer_norm.weight\n",
      "transformer.layer.1.ff.layer_norm.bias\n",
      "transformer.layer.1.ff.layer_1.weight\n",
      "transformer.layer.1.ff.layer_1.bias\n",
      "transformer.layer.1.ff.layer_2.weight\n",
      "transformer.layer.1.ff.layer_2.bias\n",
      "transformer.layer.2.rel_attn.q\n",
      "transformer.layer.2.rel_attn.k\n",
      "transformer.layer.2.rel_attn.v\n",
      "transformer.layer.2.rel_attn.o\n",
      "transformer.layer.2.rel_attn.r\n",
      "transformer.layer.2.rel_attn.r_r_bias\n",
      "transformer.layer.2.rel_attn.r_s_bias\n",
      "transformer.layer.2.rel_attn.r_w_bias\n",
      "transformer.layer.2.rel_attn.seg_embed\n",
      "transformer.layer.2.rel_attn.layer_norm.weight\n",
      "transformer.layer.2.rel_attn.layer_norm.bias\n",
      "transformer.layer.2.ff.layer_norm.weight\n",
      "transformer.layer.2.ff.layer_norm.bias\n",
      "transformer.layer.2.ff.layer_1.weight\n",
      "transformer.layer.2.ff.layer_1.bias\n",
      "transformer.layer.2.ff.layer_2.weight\n",
      "transformer.layer.2.ff.layer_2.bias\n",
      "transformer.layer.3.rel_attn.q\n",
      "transformer.layer.3.rel_attn.k\n",
      "transformer.layer.3.rel_attn.v\n",
      "transformer.layer.3.rel_attn.o\n",
      "transformer.layer.3.rel_attn.r\n",
      "transformer.layer.3.rel_attn.r_r_bias\n",
      "transformer.layer.3.rel_attn.r_s_bias\n",
      "transformer.layer.3.rel_attn.r_w_bias\n",
      "transformer.layer.3.rel_attn.seg_embed\n",
      "transformer.layer.3.rel_attn.layer_norm.weight\n",
      "transformer.layer.3.rel_attn.layer_norm.bias\n",
      "transformer.layer.3.ff.layer_norm.weight\n",
      "transformer.layer.3.ff.layer_norm.bias\n",
      "transformer.layer.3.ff.layer_1.weight\n",
      "transformer.layer.3.ff.layer_1.bias\n",
      "transformer.layer.3.ff.layer_2.weight\n",
      "transformer.layer.3.ff.layer_2.bias\n",
      "transformer.layer.4.rel_attn.q\n",
      "transformer.layer.4.rel_attn.k\n",
      "transformer.layer.4.rel_attn.v\n",
      "transformer.layer.4.rel_attn.o\n",
      "transformer.layer.4.rel_attn.r\n",
      "transformer.layer.4.rel_attn.r_r_bias\n",
      "transformer.layer.4.rel_attn.r_s_bias\n",
      "transformer.layer.4.rel_attn.r_w_bias\n",
      "transformer.layer.4.rel_attn.seg_embed\n",
      "transformer.layer.4.rel_attn.layer_norm.weight\n",
      "transformer.layer.4.rel_attn.layer_norm.bias\n",
      "transformer.layer.4.ff.layer_norm.weight\n",
      "transformer.layer.4.ff.layer_norm.bias\n",
      "transformer.layer.4.ff.layer_1.weight\n",
      "transformer.layer.4.ff.layer_1.bias\n",
      "transformer.layer.4.ff.layer_2.weight\n",
      "transformer.layer.4.ff.layer_2.bias\n",
      "transformer.layer.5.rel_attn.q\n",
      "transformer.layer.5.rel_attn.k\n",
      "transformer.layer.5.rel_attn.v\n",
      "transformer.layer.5.rel_attn.o\n",
      "transformer.layer.5.rel_attn.r\n",
      "transformer.layer.5.rel_attn.r_r_bias\n",
      "transformer.layer.5.rel_attn.r_s_bias\n",
      "transformer.layer.5.rel_attn.r_w_bias\n",
      "transformer.layer.5.rel_attn.seg_embed\n",
      "transformer.layer.5.rel_attn.layer_norm.weight\n",
      "transformer.layer.5.rel_attn.layer_norm.bias\n",
      "transformer.layer.5.ff.layer_norm.weight\n",
      "transformer.layer.5.ff.layer_norm.bias\n",
      "transformer.layer.5.ff.layer_1.weight\n",
      "transformer.layer.5.ff.layer_1.bias\n",
      "transformer.layer.5.ff.layer_2.weight\n",
      "transformer.layer.5.ff.layer_2.bias\n",
      "transformer.layer.6.rel_attn.q\n",
      "transformer.layer.6.rel_attn.k\n",
      "transformer.layer.6.rel_attn.v\n",
      "transformer.layer.6.rel_attn.o\n",
      "transformer.layer.6.rel_attn.r\n",
      "transformer.layer.6.rel_attn.r_r_bias\n",
      "transformer.layer.6.rel_attn.r_s_bias\n",
      "transformer.layer.6.rel_attn.r_w_bias\n",
      "transformer.layer.6.rel_attn.seg_embed\n",
      "transformer.layer.6.rel_attn.layer_norm.weight\n",
      "transformer.layer.6.rel_attn.layer_norm.bias\n",
      "transformer.layer.6.ff.layer_norm.weight\n",
      "transformer.layer.6.ff.layer_norm.bias\n",
      "transformer.layer.6.ff.layer_1.weight\n",
      "transformer.layer.6.ff.layer_1.bias\n",
      "transformer.layer.6.ff.layer_2.weight\n",
      "transformer.layer.6.ff.layer_2.bias\n",
      "transformer.layer.7.rel_attn.q\n",
      "transformer.layer.7.rel_attn.k\n",
      "transformer.layer.7.rel_attn.v\n",
      "transformer.layer.7.rel_attn.o\n",
      "transformer.layer.7.rel_attn.r\n",
      "transformer.layer.7.rel_attn.r_r_bias\n",
      "transformer.layer.7.rel_attn.r_s_bias\n",
      "transformer.layer.7.rel_attn.r_w_bias\n",
      "transformer.layer.7.rel_attn.seg_embed\n",
      "transformer.layer.7.rel_attn.layer_norm.weight\n",
      "transformer.layer.7.rel_attn.layer_norm.bias\n",
      "transformer.layer.7.ff.layer_norm.weight\n",
      "transformer.layer.7.ff.layer_norm.bias\n",
      "transformer.layer.7.ff.layer_1.weight\n",
      "transformer.layer.7.ff.layer_1.bias\n",
      "transformer.layer.7.ff.layer_2.weight\n",
      "transformer.layer.7.ff.layer_2.bias\n",
      "transformer.layer.8.rel_attn.q\n",
      "transformer.layer.8.rel_attn.k\n",
      "transformer.layer.8.rel_attn.v\n",
      "transformer.layer.8.rel_attn.o\n",
      "transformer.layer.8.rel_attn.r\n",
      "transformer.layer.8.rel_attn.r_r_bias\n",
      "transformer.layer.8.rel_attn.r_s_bias\n",
      "transformer.layer.8.rel_attn.r_w_bias\n",
      "transformer.layer.8.rel_attn.seg_embed\n",
      "transformer.layer.8.rel_attn.layer_norm.weight\n",
      "transformer.layer.8.rel_attn.layer_norm.bias\n",
      "transformer.layer.8.ff.layer_norm.weight\n",
      "transformer.layer.8.ff.layer_norm.bias\n",
      "transformer.layer.8.ff.layer_1.weight\n",
      "transformer.layer.8.ff.layer_1.bias\n",
      "transformer.layer.8.ff.layer_2.weight\n",
      "transformer.layer.8.ff.layer_2.bias\n",
      "transformer.layer.9.rel_attn.q\n",
      "transformer.layer.9.rel_attn.k\n",
      "transformer.layer.9.rel_attn.v\n",
      "transformer.layer.9.rel_attn.o\n",
      "transformer.layer.9.rel_attn.r\n",
      "transformer.layer.9.rel_attn.r_r_bias\n",
      "transformer.layer.9.rel_attn.r_s_bias\n",
      "transformer.layer.9.rel_attn.r_w_bias\n",
      "transformer.layer.9.rel_attn.seg_embed\n",
      "transformer.layer.9.rel_attn.layer_norm.weight\n",
      "transformer.layer.9.rel_attn.layer_norm.bias\n",
      "transformer.layer.9.ff.layer_norm.weight\n",
      "transformer.layer.9.ff.layer_norm.bias\n",
      "transformer.layer.9.ff.layer_1.weight\n",
      "transformer.layer.9.ff.layer_1.bias\n",
      "transformer.layer.9.ff.layer_2.weight\n",
      "transformer.layer.9.ff.layer_2.bias\n",
      "transformer.layer.10.rel_attn.q\n",
      "transformer.layer.10.rel_attn.k\n",
      "transformer.layer.10.rel_attn.v\n",
      "transformer.layer.10.rel_attn.o\n",
      "transformer.layer.10.rel_attn.r\n",
      "transformer.layer.10.rel_attn.r_r_bias\n",
      "transformer.layer.10.rel_attn.r_s_bias\n",
      "transformer.layer.10.rel_attn.r_w_bias\n",
      "transformer.layer.10.rel_attn.seg_embed\n",
      "transformer.layer.10.rel_attn.layer_norm.weight\n",
      "transformer.layer.10.rel_attn.layer_norm.bias\n",
      "transformer.layer.10.ff.layer_norm.weight\n",
      "transformer.layer.10.ff.layer_norm.bias\n",
      "transformer.layer.10.ff.layer_1.weight\n",
      "transformer.layer.10.ff.layer_1.bias\n",
      "transformer.layer.10.ff.layer_2.weight\n",
      "transformer.layer.10.ff.layer_2.bias\n",
      "transformer.layer.11.rel_attn.q\n",
      "transformer.layer.11.rel_attn.k\n",
      "transformer.layer.11.rel_attn.v\n",
      "transformer.layer.11.rel_attn.o\n",
      "transformer.layer.11.rel_attn.r\n",
      "transformer.layer.11.rel_attn.r_r_bias\n",
      "transformer.layer.11.rel_attn.r_s_bias\n",
      "transformer.layer.11.rel_attn.r_w_bias\n",
      "transformer.layer.11.rel_attn.seg_embed\n",
      "transformer.layer.11.rel_attn.layer_norm.weight\n",
      "transformer.layer.11.rel_attn.layer_norm.bias\n",
      "transformer.layer.11.ff.layer_norm.weight\n",
      "transformer.layer.11.ff.layer_norm.bias\n",
      "transformer.layer.11.ff.layer_1.weight\n",
      "transformer.layer.11.ff.layer_1.bias\n",
      "transformer.layer.11.ff.layer_2.weight\n",
      "transformer.layer.11.ff.layer_2.bias\n",
      "start_logits.transformer_encoder.layers.0.self_attn.in_proj_weight\n",
      "start_logits.transformer_encoder.layers.0.self_attn.in_proj_bias\n",
      "start_logits.transformer_encoder.layers.0.self_attn.out_proj.weight\n",
      "start_logits.transformer_encoder.layers.0.self_attn.out_proj.bias\n",
      "start_logits.transformer_encoder.layers.0.linear1.weight\n",
      "start_logits.transformer_encoder.layers.0.linear1.bias\n",
      "start_logits.transformer_encoder.layers.0.linear2.weight\n",
      "start_logits.transformer_encoder.layers.0.linear2.bias\n",
      "start_logits.transformer_encoder.layers.0.norm1.weight\n",
      "start_logits.transformer_encoder.layers.0.norm1.bias\n",
      "start_logits.transformer_encoder.layers.0.norm2.weight\n",
      "start_logits.transformer_encoder.layers.0.norm2.bias\n",
      "start_logits.transformer_encoder.layers.1.self_attn.in_proj_weight\n",
      "start_logits.transformer_encoder.layers.1.self_attn.in_proj_bias\n",
      "start_logits.transformer_encoder.layers.1.self_attn.out_proj.weight\n",
      "start_logits.transformer_encoder.layers.1.self_attn.out_proj.bias\n",
      "start_logits.transformer_encoder.layers.1.linear1.weight\n",
      "start_logits.transformer_encoder.layers.1.linear1.bias\n",
      "start_logits.transformer_encoder.layers.1.linear2.weight\n",
      "start_logits.transformer_encoder.layers.1.linear2.bias\n",
      "start_logits.transformer_encoder.layers.1.norm1.weight\n",
      "start_logits.transformer_encoder.layers.1.norm1.bias\n",
      "start_logits.transformer_encoder.layers.1.norm2.weight\n",
      "start_logits.transformer_encoder.layers.1.norm2.bias\n",
      "start_logits.dense_1.weight\n",
      "start_logits.dense_1.bias\n",
      "end_logits.dense_0.weight\n",
      "end_logits.dense_0.bias\n",
      "end_logits.transformer_encoder.layers.0.self_attn.in_proj_weight\n",
      "end_logits.transformer_encoder.layers.0.self_attn.in_proj_bias\n",
      "end_logits.transformer_encoder.layers.0.self_attn.out_proj.weight\n",
      "end_logits.transformer_encoder.layers.0.self_attn.out_proj.bias\n",
      "end_logits.transformer_encoder.layers.0.linear1.weight\n",
      "end_logits.transformer_encoder.layers.0.linear1.bias\n",
      "end_logits.transformer_encoder.layers.0.linear2.weight\n",
      "end_logits.transformer_encoder.layers.0.linear2.bias\n",
      "end_logits.transformer_encoder.layers.0.norm1.weight\n",
      "end_logits.transformer_encoder.layers.0.norm1.bias\n",
      "end_logits.transformer_encoder.layers.0.norm2.weight\n",
      "end_logits.transformer_encoder.layers.0.norm2.bias\n",
      "end_logits.transformer_encoder.layers.1.self_attn.in_proj_weight\n",
      "end_logits.transformer_encoder.layers.1.self_attn.in_proj_bias\n",
      "end_logits.transformer_encoder.layers.1.self_attn.out_proj.weight\n",
      "end_logits.transformer_encoder.layers.1.self_attn.out_proj.bias\n",
      "end_logits.transformer_encoder.layers.1.linear1.weight\n",
      "end_logits.transformer_encoder.layers.1.linear1.bias\n",
      "end_logits.transformer_encoder.layers.1.linear2.weight\n",
      "end_logits.transformer_encoder.layers.1.linear2.bias\n",
      "end_logits.transformer_encoder.layers.1.norm1.weight\n",
      "end_logits.transformer_encoder.layers.1.norm1.bias\n",
      "end_logits.transformer_encoder.layers.1.norm2.weight\n",
      "end_logits.transformer_encoder.layers.1.norm2.bias\n",
      "end_logits.LayerNorm.weight\n",
      "end_logits.LayerNorm.bias\n",
      "end_logits.dense_1.weight\n",
      "end_logits.dense_1.bias\n",
      "answer_class.dense.weight\n",
      "answer_class.dense.bias\n"
     ]
    }
   ],
   "source": [
    "for i in model.state_dict().keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = tokenizer.batch_encode_plus([\n",
    "                                ('helolo', 'i am '),\n",
    "                                ('sss', 'dddd')\n",
    "                            ], return_tensors='pt',\n",
    "                            pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 768])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**xx)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "src = torch.rand(10, 32, 512)\n",
    "out = transformer_encoder(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.functional.leaky_relu?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 排列组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sss hhh aaa',\n",
       " 'hhh aaa sss',\n",
       " 'hhh sss aaa',\n",
       " 'aaa hhh sss',\n",
       " 'sss aaa hhh',\n",
       " 'aaa sss hhh']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ['hhh', 'aaa', 'sss', 'ffff']\n",
    "p = [' '.join(i) for i in permutations(x[:3],3)]\n",
    "np.random.shuffle(p)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hhh aaa sss',\n",
       " 'aaa hhh sss',\n",
       " 'sss hhh aaa',\n",
       " 'sss aaa hhh',\n",
       " 'hhh sss aaa',\n",
       " 'aaa sss hhh']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = [' '.join(i) for i in p]\n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn([3,12])\n",
    "i = torch.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9562],\n",
       "        [-1.1158],\n",
       "        [ 0.6481]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.gather(-1, i.view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, -99, -99, -99, -99, -99, -99, 2, 2, 5, 5, 5, 5, 5]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_id = [0,1,1,1,1,1,2,2,5,5,5,5,5]\n",
    "BOS = 0\n",
    "EOS = 2\n",
    "for start in range(len(inputs_id)):\n",
    "    if inputs_id[start] != BOS: continue\n",
    "    for end in range(start+1, len(inputs_id)):\n",
    "        if inputs_id[end] != EOS: continue\n",
    "        inputs_id[start+1:end] = [-99 for _ in range(end-start)]\n",
    "        break\n",
    "    break\n",
    "inputs_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Fine tuning LM for QA",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "218.275px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
