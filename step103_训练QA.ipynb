{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>训练QA<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#初始化\" data-toc-modified-id=\"初始化-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>初始化</a></span></li><li><span><a href=\"#QA-dataset\" data-toc-modified-id=\"QA-dataset-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>QA dataset</a></span></li><li><span><a href=\"#QA-model\" data-toc-modified-id=\"QA-model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>QA model</a></span></li><li><span><a href=\"#训练\" data-toc-modified-id=\"训练-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>训练</a></span><ul class=\"toc-item\"><li><span><a href=\"#超参数\" data-toc-modified-id=\"超参数-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>超参数</a></span></li><li><span><a href=\"#辅助函数\" data-toc-modified-id=\"辅助函数-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>辅助函数</a></span></li><li><span><a href=\"#实例化\" data-toc-modified-id=\"实例化-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>实例化</a></span></li><li><span><a href=\"#开始训练\" data-toc-modified-id=\"开始训练-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>开始训练</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from argparse import Namespace\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import ujson as json\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from apex import amp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "from datasets import HotpotQA_QA_Dataset, find_ans_spans, generate_QA_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from XLNET_QA import XLNetForQuestionAnswering_customized as XLNetQAModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     6
    ]
   },
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    json_train_path=r'./data/hotpot_train_v1.1.json',\n",
    "    json_train_mini_path=r'./data/hotpot_train_mini.json',\n",
    "    model_state_file = \"HotpotQA_QA.pt\",\n",
    "    save_dir = 'save_cache',\n",
    "    hotpotQA_item_folder = 'save_preprocess_new',\n",
    "    model_path = '/g/data/models/xlnet-large-cased',\n",
    "    use_proxy = False,\n",
    "    proxies={\"http_proxy\": \"127.0.0.1:10809\",\n",
    "             \"https_proxy\": \"127.0.0.1:10809\"},\n",
    "\n",
    "    # Training hyper parameter\n",
    "    num_epochs=10,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=32,\n",
    "    seed=1337,\n",
    "    early_stopping_criteria=5,\n",
    "\n",
    "    # Runtime hyper parameter\n",
    "    cuda=True,\n",
    "    device=None,\n",
    "    catch_keyboard_interrupt=True,\n",
    "    reload_from_files=True,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     6,
     10,
     13,
     16
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "if not args.device:\n",
    "    args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.model_state_file = os.path.join(args.save_dir,args.model_state_file)\n",
    "\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "handle_dirs(args.save_dir)\n",
    "\n",
    "print(\"Using: {}\".format(args.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     21,
     64,
     82
    ]
   },
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            \n",
    "            'train_running_loss': [],\n",
    "            'train_running_ans_span_accuracy': [],\n",
    "            'train_running_yes_no_span_accuracy': [],\n",
    "            \n",
    "            'val_running_loss': [],\n",
    "            'val_running_ans_span_accuracy': [],\n",
    "            'val_running_yes_no_span_accuracy': [],\n",
    "\n",
    "            'test_running_loss': [],\n",
    "            'test_running_ans_span_accuracy': [],\n",
    "            'test_running_yes_no_span_accuracy': [],\n",
    "\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, optimizer, train_state):\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        checkpoint = {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'amp': amp.state_dict()\n",
    "        }\n",
    "        torch.save(checkpoint, train_state['model_filename'])\n",
    "        \n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_running_loss'][-2:]\n",
    "         \n",
    "        # If loss worsened\n",
    "        if loss_t >= loss_tm1:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                \n",
    "                checkpoint = {\n",
    "                    'model': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'amp': amp.state_dict()\n",
    "                }\n",
    "                torch.save(checkpoint, train_state['model_filename'])\n",
    "\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def compute_span_accuracy(start_logits, start_positions, end_logits, end_positions):\n",
    "\n",
    "    _, start_indices = start_logits.max(-1)\n",
    "    start_indices.eq(start_positions)\n",
    "\n",
    "    _, end_indices = end_logits.max(-1)\n",
    "    end_indices.eq(end_positions)\n",
    "\n",
    "    correct = start_indices.eq(start_positions) * end_indices.eq(end_positions)\n",
    "\n",
    "    numerator = correct.sum().item()\n",
    "    denominator = start_positions.ne(-100).sum().item()\n",
    "\n",
    "    # all questions are yes-no type.\n",
    "    if denominator == 0: return 0\n",
    "\n",
    "    return float(numerator) / denominator\n",
    "\n",
    "def compute_accuracy(logits, labels):\n",
    "\n",
    "    _, logits_indices = logits.max(-1)    \n",
    "\n",
    "    numerator = torch.eq(logits_indices, labels).sum().item()\n",
    "    denominator = labels.ne(-100).sum().item()\n",
    "\n",
    "    if denominator == 0: return 0\n",
    "    return float(numerator) / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实例化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "tokenizer_XLNET = AutoTokenizer.from_pretrained(args.model_path)\n",
    "classifier = XLNetQAModel.from_pretrained(args.model_path, local_files_only=True)\n",
    "classifier = classifier.to(args.device)\n",
    "classifier.train()\n",
    "\n",
    "loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, classifier.parameters()),\n",
    "                      lr=args.learning_rate)\n",
    "\n",
    "# Initialization\n",
    "opt_level = 'O1'\n",
    "classifier, optimizer = amp.initialize(classifier, optimizer, opt_level=opt_level)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\\\n",
    "                        mode='min', factor=0.5, patience=3)\n",
    "\n",
    "train_state = make_train_state(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HotpotQA QA Dataset. mode: train. size: 63312. sents num: 6\n"
     ]
    }
   ],
   "source": [
    "dataset = HotpotQA_QA_Dataset.build_dataset(args.json_train_path)\n",
    "dataset.set_parameters(tokenizer = tokenizer_XLNET, topN_sents = 6)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6dba3b14d61443d9b8766b97751ec61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='training routine', max=10.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20eb66afe224feabdbb5ac79986bbae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=train', max=1978.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4fa7ec3fd24c3b827f51873150589f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=val', max=847.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
      "Exiting loop\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    epoch_bar = tqdm(desc='training routine',\n",
    "                    total=args.num_epochs,\n",
    "                    position=0)\n",
    "\n",
    "    dataset.set_split('train')\n",
    "    train_bar = tqdm(desc='split=train',\n",
    "                    total=dataset.get_num_batches(args.batch_size), \n",
    "                    position=1)\n",
    "\n",
    "    dataset.set_split('val')\n",
    "    val_bar = tqdm(desc='split=val',\n",
    "                    total=dataset.get_num_batches(args.batch_size), \n",
    "                    position=1)\n",
    "\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_QA_batches(dataset,\n",
    "                                        batch_size=args.batch_size, \n",
    "                                        device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_ans_span_accuracy = 0.0\n",
    "        running_yes_no_span_accuracy = 0.0\n",
    "\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            optimizer.zero_grad()\n",
    "            yes_no_span = batch_dict.pop('yes_no_span')\n",
    "            res = classifier(**batch_dict)\n",
    "            start_logits, end_logits, cls_logits = res[0], res[1], res[2]\n",
    "            \n",
    "            start_loss = loss_fct(start_logits, batch_dict['start_positions'])\n",
    "            end_loss = loss_fct(end_logits, batch_dict['end_positions'])\n",
    "            start_end_loss = (start_loss + end_loss) / 2\n",
    "            yes_no_span_loss = loss_fct(cls_logits, yes_no_span) / 2\n",
    "\n",
    "            ans_span_accuracy = compute_span_accuracy(start_logits, batch_dict['start_positions'],\n",
    "                                                        end_logits, batch_dict['end_positions'])\n",
    "            yes_no_span_accuracy = compute_accuracy(cls_logits, yes_no_span)\n",
    "            \n",
    "            loss = start_end_loss + yes_no_span_loss\n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "            running_ans_span_accuracy  += (ans_span_accuracy - running_ans_span_accuracy) / (batch_index + 1)\n",
    "            running_yes_no_span_accuracy  += (yes_no_span_accuracy - running_yes_no_span_accuracy) / (batch_index + 1)\n",
    "            \n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            # update bar\n",
    "            train_bar.set_postfix(running_loss=running_loss,\n",
    "                                  running_ans_span_accuracy=running_ans_span_accuracy,\n",
    "                                  running_yes_no_span_accuracy=running_yes_no_span_accuracy,\n",
    "                                  epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_running_loss'].append(running_loss)\n",
    "        train_state['train_running_ans_span_accuracy'].append(running_ans_span_accuracy)\n",
    "        train_state['train_running_yes_no_span_accuracy'].append(running_yes_no_span_accuracy)\n",
    "\n",
    "        # Iterate over val dataset\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_QA_batches(dataset,\n",
    "                                        batch_size=args.batch_size, \n",
    "                                        device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_ans_span_accuracy = 0.0\n",
    "        running_yes_no_span_accuracy = 0.0\n",
    "        \n",
    "        classifier.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            with torch.no_grad():\n",
    "\n",
    "                yes_no_span = batch_dict.pop('yes_no_span')\n",
    "                res = classifier(**batch_dict)\n",
    "                start_logits, end_logits, cls_logits = res[0], res[1], res[2]\n",
    "\n",
    "                start_loss = loss_fct(start_logits, batch_dict['start_positions'])\n",
    "                end_loss = loss_fct(end_logits, batch_dict['end_positions'])\n",
    "                start_end_loss = (start_loss + end_loss) / 2\n",
    "                yes_no_span_loss = loss_fct(cls_logits, yes_no_span) / 2\n",
    "\n",
    "                ans_span_accuracy = compute_span_accuracy(start_logits, batch_dict['start_positions'],\n",
    "                                                            end_logits, batch_dict['end_positions'])\n",
    "                yes_no_span_accuracy = compute_accuracy(cls_logits, yes_no_span)\n",
    "\n",
    "                loss = start_end_loss + yes_no_span_loss\n",
    "                running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "                running_ans_span_accuracy  += (ans_span_accuracy - running_ans_span_accuracy) / (batch_index + 1)\n",
    "                running_yes_no_span_accuracy  += (yes_no_span_accuracy - running_yes_no_span_accuracy) / (batch_index + 1)\n",
    "\n",
    "\n",
    "\n",
    "            val_bar.set_postfix(running_loss=running_loss,\n",
    "                                  running_ans_span_accuracy=running_ans_span_accuracy,\n",
    "                                  running_yes_no_span_accuracy=running_yes_no_span_accuracy,\n",
    "                                  epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_running_loss'].append(running_loss)\n",
    "        train_state['val_running_ans_span_accuracy'].append(running_ans_span_accuracy)\n",
    "        train_state['val_running_yes_no_span_accuracy'].append(running_yes_no_span_accuracy)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=classifier, \n",
    "                                         optimizer = optimizer,\n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_running_loss'][-1])\n",
    "\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "训练QA",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
